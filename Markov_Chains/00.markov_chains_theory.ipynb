{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Markov Chains Theory",
   "id": "18fbab7393328730"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Definitions\n",
    "\n",
    "A Markov chain describes a system whose state changes over time. The changes are not completely predictable, but rather are governed by probability distributions. These probability distributions incorporate a simple sort of dependence structure, where the conditional distribution of future states of the system, given some information about past states, depends only on the most recent piece of information. That is, what matters in\n",
    "predicting the future of the system is its present state, and not the path by which the system got to its present state. [1]\n",
    "\n",
    "\n",
    "Markov chain is a sequence of random variable $X_1$, $X_2$, $X_3$,... such that the distribution of $X_t+1$ conditioned on $X_1, ..., X_t$ only depends on $X_t$ and not on the values of $X_1, ..., X_t-1$. [2]\n"
   ],
   "id": "78867e97cd9731a1"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Sources\n",
    "1. [Chang, J. (2007). *Stochastic Processes*.](http://www.stat.yale.edu/~pollard/Courses/251.spring2013/Handouts/Chang-notes.pdf)\n",
    "2. [Shapiro, I., Huber, M. (2021). *Markov Chains for Computer Music Generation*. Journal of Humanistic\n",
    "Mathematics, Volume 11 Issue 2.](https://scholarship.claremont.edu/jhm/vol11/iss2/8)"
   ],
   "id": "7c50907cc79f30b1"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
