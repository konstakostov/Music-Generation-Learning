{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Markov Chains Theory",
   "id": "18fbab7393328730"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Definitions\n",
    "\n",
    "A Markov chain describes a system whose state changes over time. The changes are not completely predictable, but rather are governed by probability distributions. These probability distributions incorporate a simple sort of dependence structure, where the conditional distribution of future states of the system, given some information about past states, depends only on the most recent piece of information. That is, what matters in\n",
    "predicting the future of the system is its present state, and not the path by which the system got to its present state. [1]\n",
    "\n",
    "\n",
    "Markov chain is a sequence of random variable $X_1$, $X_2$, $X_3$,... such that the distribution of $X_t+1$ conditioned on $X_1, ..., X_t$ only depends on $X_t$ and not on the values of $X_1, ..., X_t-1$. [2]\n",
    "\n",
    "\n",
    "A Markov chain is **memoryless process**, since the next state depends purely on the current state, and not on the memory of the notes that came before [2].\n",
    "\n",
    "Markov chains can be represented by:\n",
    "* Transition Matrx;\n",
    "* Graphically, via directed graph. [2]"
   ],
   "id": "78867e97cd9731a1"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## The Markov Frog\n",
    "\n",
    "The Markov frog is a graphical representation of a Markov chain. There are three lilly pads (each representing a node), and each arrow has a weight coefficient, representing the probability of the frog jumping on one of the pads. \n",
    "* The future state depends **only** on the current state.\n",
    "* When using a Markov chain, there is **no memory of previous states**, before the current state.\n",
    "\n",
    "<p>\n",
    "    <img src=\"01.markovs_frog.png\" alt=\"The Markov Frog [1]\" width=\"480\" height=\"360\">\n",
    "</p> [1]"
   ],
   "id": "8929eda3fd19ec43"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Markov Chains for Music Generation\n",
    "\n",
    "Markov chains can be used to generate music. Some of the ways to achieve that are: \n",
    "1. Generate a completely random set of notes (selecting a random note from pre-defined allowed notes to follow the current note) that can result in generating a piece of music.\n",
    "2. Using an already existing piece of music to generate music in the same genre/style as the original piece of music.\n",
    "\n",
    "If it is decided to use a given piece of music as the original piece, it will be used and called the *training data*. This data will be used to estimate the probabilities for the Markov chain. Each node will represent ***sound objects****, that will contain data about: \n",
    "* Single note name or a collection of notes in the chord (using note names A through G);\n",
    "* Each note can be natural, sharp `#` or flat `b`); \n",
    "* The octave of each note, represented by integer value (0â€“8); \n",
    "* The duration for each of the notes can be denoted by whole note, half-note, quarter-note, etc.\n",
    "\n",
    "Between notes/chords can occur be rests (pauses), which are defined by not playing any sounds.\n",
    "\n",
    "By parsing through our test data, the Markov chain will be created, and it will determine the different nodes and their probability chance to occur following the current one.\n",
    "\n",
    "***Sound Objects****: Entity that represents a single note/chord and containing information about its pitch(es), octave(s) and duration"
   ],
   "id": "88e8b66c650f6841"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Sources\n",
    "1. [Chang, J. (2007). *Stochastic Processes*.](http://www.stat.yale.edu/~pollard/Courses/251.spring2013/Handouts/Chang-notes.pdf)\n",
    "2. [Shapiro, I., Huber, M. (2021). *Markov Chains for Computer Music Generation*. Journal of Humanistic\n",
    "Mathematics, Volume 11 Issue 2.](https://scholarship.claremont.edu/jhm/vol11/iss2/8)"
   ],
   "id": "7c50907cc79f30b1"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
